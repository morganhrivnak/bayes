---
title: "biol792ch7hw"
author: "morgan hrivnak"
date: "2024-10-02"
output: html_document
---
7E1. 
Three motivating criteria that define information entropy are based on unpredictable outcomes carrying more information. Randomness is essential to defining information entropy. The average information per message element tells us that less probably events contribute more to overall entropy. Minimum encoding requirements ensure that we have accurate representation.These three criteria help us to understand information entropy and how they relate to model selection criteria. 

7E2.
```{r}
p <- c(0.7, 0.3)
-sum(p * log(p))
```

7E3.
```{r}
p <- c(0.2, 0.25, 0.25, 0.3)
-sum(p * log(p))
```

7E4.
```{r}
p <- c(1 / 3, 1 / 3, 1 / 3)
-sum(p * log(p))
```

7M1.

AIC = Dtrain + 2p = 2lppd + 2p
Dtrain is the sample deviance 
p is the number of parameters estimated in the model

WAIC = -2(lppd - E varlogp(y|0))
y is the observation 
0 is the posterior distribution
everything in the parenthese is the pointwise-predictive density

WAIC is a more general method because it is built on the assumption that sample size > number of parameters while AIC is also built on this assumption but also the assumptions that priors are flat and posterior distribution is Gaussian.

7M2. 

#can we go over this in class I am still kind of confused :)

Model selection is when you select the optimal number of clusters, it selects the most likely model from a set of competting hypotheses. Model comparison is when you assign prior probabilities to models and update them based on data. Fundamentally they are different approaches to showing data and can be used to understand relationships of different models.

7M3.
Information criteria are based on deviance, deviance is the sum of observations not the mean product. When everyhting else is equal the higher the observation the higher the deviance creating worse accuracy.

7M4. 
As priors become regularized the number of parameters decreases. When WAIC has concentrated priors they constrain and thus reudce the likelihood and variance. When PSIS has has regularized priors the model becomes less flexible.

7M5. 
Information priors constrain the model. When you constrain the model it makes it harder to see an extreme parameter.

7M6.
Informative priors result in underfitting because a model is too simple and cannot define a dominant trend within the data. This happens when priors aren't chosen carifully or weakly defined. 


